# DeepSeek-V3.2-Exp

> **Type** : TECHNOLOGIE | 5 relations | 1 fiches sources

## Attributs

- **architecture** : Mixture-of-experts, 685B paramètres, ~37B actifs
- **licence** : MIT (commercial et non-commercial)

## Relations (comme sujet)

### est_basé_sur

- [[kb/_entites-mineures#DeepSeek-V3.1-Terminus\|DeepSeek-V3.1-Terminus]] (TECHNOLOGIE) — 0.98, STATIQUE
  - [[fiches/2025-10/deepseek-openai-amd-finetuning-batch-323-2025-10-15\|Newsletter IA - réduction coûts inférence - partenariats hardware - simplification fine-tuning - DeepLearning.AI]]

### réduit

- [[kb/_entites-mineures#coûts_inférence\|coûts_inférence]] (CONCEPT) — 0.98, STATIQUE
  - [[fiches/2025-10/deepseek-openai-amd-finetuning-batch-323-2025-10-15\|Newsletter IA - réduction coûts inférence - partenariats hardware - simplification fine-tuning - DeepLearning.AI]]

### supporte

- [[kb/_entites-mineures#puces_Huawei\|puces_Huawei]] (TECHNOLOGIE) — 0.93, STATIQUE
  - [[fiches/2025-10/deepseek-openai-amd-finetuning-batch-323-2025-10-15\|Newsletter IA - réduction coûts inférence - partenariats hardware - simplification fine-tuning - DeepLearning.AI]]

### utilise

- [[kb/_entites-mineures#attention_sparse_dynamique\|attention_sparse_dynamique]] (CONCEPT) — 0.97, STATIQUE
  - [[fiches/2025-10/deepseek-openai-amd-finetuning-batch-323-2025-10-15\|Newsletter IA - réduction coûts inférence - partenariats hardware - simplification fine-tuning - DeepLearning.AI]]

## Relations (comme objet)

- [[kb/_entites-mineures#DeepSeek\|DeepSeek]] **publie** → DeepSeek-V3.2-Exp — 0.99

## Fiches sources

- [[fiches/2025-10/deepseek-openai-amd-finetuning-batch-323-2025-10-15\|Newsletter IA - réduction coûts inférence - partenariats hardware - simplification fine-tuning - DeepLearning.AI]]
