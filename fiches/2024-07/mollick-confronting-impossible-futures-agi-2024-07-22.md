# mollick-confronting-impossible-futures-agi-2024-07-22

## Veille
Planification stratégique face aux futurs impossibles de l'IA et de l'AGI - One Useful Thing - Ethan Mollick

## Titre Article
Confronting Impossible Futures

## Date
2024-07-22

## URL
https://www.oneusefulthing.org/p/confronting-impossible-futures

## Keywords
AGI, Intelligence Artificielle Générale, planification stratégique, LLM, adoption IA, scénarios futurs, transformation organisationnelle, incertitude technologique, loi de Moore, disruption

## Authors
Ethan Mollick, Professeur à la Wharton School, University of Pennsylvania

## Ton
**Profil:** Académique-Prospectif | Première personne thought leader | Analytique-Provocatrice | Intermédiaire

Mollick adopte ton essayiste intellectuel combinant data empirique (sondages AGI 2047) et réflexion stratégique. Titre "Confronting Impossible Futures" signals willingness aborder uncomfortable scenarios. Langage accessible évite jargon technique excessif tout en covering complex AGI implications. Structure argument méthodique identifiant obstacles (discussions dystopiques, documentation manquante, fragmentation progrès) puis proposing frameworks action. Tone measured urgency évitant both dismissive skepticism et panicked alarmism. Typique Substack thoughtful essays (Stratechery, Margins style) challenging conventional wisdom et forcing readers confront difficult questions sur technological trajectory.

## Pense-bêtes
- Les organisations planifient sur 10 ans mais ignorent l'amélioration continue de l'IA dans leurs stratégies
- Même sans nouvelles avancées, l'IA actuelle disruptera les organisations pendant des années
- Sondage 2023 : AGI prévue en moyenne pour 2047, avec 10% de probabilité avant 2027
- Trois obstacles à l'action : discussions dystopiques paralysantes, manque de documentation claire, nature fragmentaire des progrès
- La loi de Moore comme exemple de prophétie autoréalisatrice : les attentes deviennent des objectifs motivateurs
- Recommandation : planification multi-scénarios (plateau, croissance linéaire, croissance exponentielle, AGI)
- L'incertitude sur le chronogramme ne justifie pas l'inaction
- Les outils d'IA modernes peuvent faciliter la planification de scénarios
- Fonctionnalités IA impressionnantes cachées derrière interfaces non-intuitives
- Les critiques minimisent facilement les capacités réelles en se concentrant sur les échecs ponctuels

## RésuméDe400mots

Ethan Mollick examine un paradoxe troublant : malgré des horizons de planification s'étendant sur une décennie, peu d'organisations intègrent sérieusement la possibilité d'une amélioration continue de l'IA dans leurs stratégies. Cette omission surprend d'autant plus que les experts divergent sur l'avenir de l'IA—certains prédisent une croissance exponentielle imminente, d'autres affirment que les modèles de langage ont atteint leurs limites.

L'auteur souligne que même sans avancées technologiques supplémentaires, l'IA disrupterait significativement les organisations pendant des années. Les systèmes d'IA nécessitent une meilleure intégration, tandis qu'un arrêt complet du développement semble improbable. Les impacts actuels—automatisation professionnelle, campagnes de phishing ciblées, modifications pédagogiques—demandent une attention immédiate.

Mollick établit un parallèle instructif avec la loi de Moore, montrant comment les attentes technologiques deviennent des objectifs motivateurs, créant des prophéties autoréalisatrices. Les dirigeants d'IA annoncent des délais ambitieux (2027, cinq ans), bien que les avis divergent. Un sondage de 2023 parmi informaticiens situe la date moyenne de l'AGI à 2047, avec dix pour cent de probabilité avant 2027.

Trois obstacles principaux expliquent l'inaction organisationnelle. Premièrement, les discussions dystopiques sur la superintelligence paraissent inplanifiables. Deuxièmement, l'absence remarquable de documentation claire pour non-spécialistes perpétue l'ignorance des capacités actuelles. Les fonctionnalités impressionnantes restent cachées derrière des interfaces non-intuitives ou des conseils obscurs.

Troisièmement, la nature fragmentaire des progrès IA—excellente dans certains domaines, décevante ailleurs—permet facilement de minimiser les capacités réelles. Mollick illustre cette tendance en citant des critiques qui, tout en reconnaissant les accomplissements remarquables, nient leur signification transformatrice.

L'auteur propose d'abandonner cette paralysie par l'incertitude. Plutôt que de choisir une vision unique du futur, les organisations devraient planifier plusieurs scénarios possibles : plateau technique, croissance linéaire, croissance exponentielle, ou AGI. Il recommande la planification de scénarios, processus qu'il démontre être facilitée par les outils d'IA modernes.

En conclusion, Mollick plaide pour reconnaître le changement inévitable et prendre activement le contrôle de sa direction. L'incertitude concernant le chronogramme exact ne justifie pas l'inaction. Les organisations doivent commencer dès maintenant à envisager des futurs radicalement différents et adapter leurs stratégies en conséquence.

## GrapheDeConnaissance

### Triples

| Sujet | Type Sujet | Prédicat | Objet | Type Objet | Confiance | Temporalité | Source |
|-------|-----------|----------|-------|-----------|-----------|-------------|--------|
| Ethan Mollick | PERSONNE | enseigne_à | Wharton School | ORGANISATION | 0.99 | DYNAMIQUE | déclaré_article |
| Ethan Mollick | PERSONNE | prédit | organisations doivent planifier plusieurs scénarios AGI | CONCEPT | 0.95 | STATIQUE | déclaré_article |
| organisations | CONCEPT | ignorent | amélioration continue de l'IA dans la planification | CONCEPT | 0.92 | DYNAMIQUE | déclaré_article |
| AGI | CONCEPT | représente | objectif des grands laboratoires IA | CONCEPT | 0.97 | STATIQUE | déclaré_article |
| loi de Moore | CONCEPT | illustre | prophétie autoréalisatrice technologique | CONCEPT | 0.90 | ATEMPOREL | déclaré_article |
| Ethan Mollick | PERSONNE | recommande | planification multi-scénarios | METHODOLOGIE | 0.95 | STATIQUE | déclaré_article |
| Arvind Narayanan | PERSONNE | contredit | timelines AGI courtes | CONCEPT | 0.85 | STATIQUE | déclaré_article |
| sondage informaticiens 2023 | EVENEMENT | situe | AGI en moyenne à 2047 | CONCEPT | 0.92 | STATIQUE | déclaré_article |
| Claude 3.5 | TECHNOLOGIE | démontre | capacités IA actuelles impressionnantes | CONCEPT | 0.88 | STATIQUE | déclaré_article |
| GPT-4o | TECHNOLOGIE | facilite | planification de scénarios | METHODOLOGIE | 0.83 | DYNAMIQUE | déclaré_article |
| Ethan Mollick | PERSONNE | a_publié | Co-Intelligence | DOCUMENT | 0.95 | STATIQUE | déclaré_article |

### Entités

| Entité | Type | Attribut | Valeur | Action |
|--------|------|----------|--------|--------|
| Ethan Mollick | PERSONNE | rôle | Professeur Wharton School, auteur One Useful Thing | AJOUT |
| AGI | CONCEPT | définition | IA surpassant humains dans toutes tâches | AJOUT |
| Wharton School | ORGANISATION | type | École de commerce, Université de Pennsylvanie | AJOUT |
| loi de Moore | CONCEPT | analogie | Attentes technologiques devenant objectifs motivateurs | AJOUT |
| planification multi-scénarios | METHODOLOGIE | application | Plateau, croissance linéaire, exponentielle, AGI | AJOUT |
| Co-Intelligence | DOCUMENT | type | Livre, nommé meilleur livre 2024 par Amazon et The Economist | AJOUT |
| Arvind Narayanan | PERSONNE | affiliation | Chercheur indépendant, timelines AGI longues | AJOUT |
