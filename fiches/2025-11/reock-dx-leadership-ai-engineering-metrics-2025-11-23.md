# reock-dx-leadership-ai-engineering-metrics-2025-11-23
## Veille
DX Platform - Engineering Leadership - Productivity Metrics - Psychological Safety - SDLC Constraints

## Titre Article
Effective Leadership in AI-Enhanced Organizations

## Date
2025-11-23

## URL
https://www.youtube.com/live/cMSprbJ95jg?si=4HnxK8w1ELvSr4tz&t=27241

## Keywords
DX, Engineering Leadership, AI Metrics, Psychological Safety, SDLC, Theory of Constraints, Developer Experience, Change Failure Rate

## Authors
Justin Reock (Deputy CTO, DX)

## Ton
**Profil:** Leadership-Humain | Analytique-Systémique | Éducatif | Bienveillant

Justin Reock adopte un ton axé sur le leadership éclairé. Il s'appuie sur des données (Dora, DX data) pour déconstruire les idées reçues (l'IA augmente toujours la productivité). Il insiste beaucoup sur l'aspect humain (sécurité psychologique, peur du remplacement) et systémique (théorie des contraintes). C'est un discours pour les managers qui veulent réussir l'adoption de l'IA sans brûler leurs équipes.

## Pense-betes
- **Volatilité de l'impact** : Les moyennes cachent la réalité. Si la moyenne montre un léger gain, les données par entreprise montrent une volatilité extrême (+20% à -20% de confiance). Certaines entreprises voient leur "Change Failure Rate" augmenter significativement.
- **L'importance de la Sécurité Psychologique** : Projet Aristotle (Google). L'IA fait peur (remplacement). Les mandats top-down ne marchent pas. Il faut rassurer : l'IA est là pour augmenter, pas remplacer (l'IA échoue encore sur 2/3 des tâches complexes SWE-bench).
- **Mesure de l'impact (Framework DX)** :
    - **Télémetrie** (ce qui se passe) vs **Survey/Self-reported** (ce que les gens ressentent/le contexte).
    - Métriques clés : Change Failure Rate, Change Confidence, Maintainability.
    - Ne pas se fier uniquement à l'utilisation (copilot adoption).
- **Théorie des Contraintes** : Gagner du temps sur le codage ne sert à rien si le goulot d'étranglement est ailleurs (réunions, attente de specs, déploiement).
    - Exemples : Morgan Stanley (Legacy code reverse engineering), Zapier (Onboarding accéléré), Spotify (Incident context).
- **Conseils Leadership** :
    - Unblock usage (Sandbox sécurisée).
    - Feedback loop sur les System Prompts (gardien des règles).
    - Temperature awareness (créativité vs déterminisme).

## RésuméDe400mots
Justin Reock, Deputy CTO chez DX, aborde le défi du leadership dans les organisations adoptant l'IA. Il commence par déconstruire les moyennes rassurantes de l'industrie : si l'on voit globalement de légers gains de productivité, les données granulaires par entreprise révèlent une **volatilité extrême**. Certaines organisations voient leur taux d'échec (Change Failure Rate) augmenter et la confiance de leurs développeurs s'effondrer.

Pour réussir, Reock insiste sur la **sécurité psychologique** (référence au Projet Aristotle de Google). L'IA génère de la peur (remplacement). Les leaders doivent communiquer clairement que l'objectif est l'augmentation des capacités, pas la réduction d'effectifs, d'autant que les agents échouent encore sur la majorité des tâches complexes autonomes. Les mandats "top-down" sont contre-productifs.

Il propose un framework de mesure équilibrant **télémétrie** (ce qui se passe techniquement) et **données qualitatives** (ressenti développeur), car 95% de la productivité dépend du système, pas de l'individu. Il met en garde contre l'obsession du "temps de codage gagné". Citant la **Théorie des Contraintes** (Goldratt), il rappelle que gagner une heure sur une tâche qui n'est pas le goulot d'étranglement est inutile.

Il cite des exemples d'entreprises ayant ciblé les bons goulots :
- **Morgan Stanley** utilise l'IA pour rétro-ingénierier le code legacy (Cobol), débloquant la modernisation.
- **Zapier** utilise des bots pour l'onboarding, rendant les nouveaux ingénieurs productifs en 2 semaines (vs 90 jours).
- **Spotify** accélère la résolution d'incidents en poussant le contexte automatiquement aux SRE.

Enfin, il donne des conseils tactiques pour les leaders : établir des boucles de feedback sur les "System Prompts" (pour que les règles de l'IA soient maintenues comme du code), comprendre les paramètres comme la "température" (créativité vs déterminisme), et surtout, fournir des espaces sécurisés (sandboxes) pour que les équipes puissent expérimenter sans peur.
