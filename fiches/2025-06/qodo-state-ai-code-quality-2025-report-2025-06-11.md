# qodo-state-ai-code-quality-2025-report-2025-06-11

## Veille
Qodo - State of AI code quality 2025 - Hallucinations - Context - Developer confidence - Survey report

## Titre Article
State of AI code quality in 2025 - Qodo

## Date
2025-06-11

## URL
https://www.qodo.ai/reports/state-of-ai-code-quality/

## Keywords
AI code quality, AI coding, AI tools, software development, developer productivity, code review, AI testing, hallucinations, contextual understanding, developer confidence, Qodo, GenAI, SDLC, code generation, code integrity

## Authors
Itamar Friedman (Co-founder & CEO, Qodo)

## Pense-betes
- **609 développeurs** sondés en 2025
- **82%** utilisent AI daily/weekly, **59%** utilisent 3+ outils
- **65%** des commits shapés/générés par IA (>25% du code en production)
- **78%** reportent gains productivité, **57%** jobs plus enjoyables
- **25%** estiment **1 sur 5 suggestions IA** contient erreurs (hallucinations)
- **76%** low confidence shipping AI code sans checks humains (même avec low hallucinations)
- **70%** gros gains productivité voient aussi improved code quality
- **81%** fast teams utilisant AI review voient quality improvements (vs 55% sans)
- **Context = #1 driver** de qualité et trust perçus
- **65%** devs disent AI miss relevant context pendant refactoring
- **Confidence Flywheel** : context-rich → moins hallucinations → accurate code → trust → faster shipping → better examples → amélioration continue
- Seulement **3.8%** expérimentent Confidence Flywheel idéal
- **61% vs 27%** : devs utilisant AI pour testing ont 2x plus confiance dans test suites

## RésuméDe400mots

Le rapport "State of AI Code Quality in 2025" de Qodo, basé sur survey de **609 développeurs**, explore l'évolution du rôle de l'IA dans développement logiciel, soulignant que bien que AI tools sont devenus mainstream (82% utilisation daily/weekly, 59% utilisent 3+ outils), deep trust dans leur output reste élusive. Les outils IA influencent significativement production code : 65% des développeurs déclarent qu'au moins 25% de leurs commits sont AI-generated ou shaped.

**Productivité vs Confiance : Le Paradoxe**

Bien que 78% reportent gains productivité et 57% trouvent jobs plus enjoyables, une barrière majeure persiste : hallucinations. **25% des développeurs** estiment qu'une sur cinq suggestions IA contient erreurs, impactant significativement confiance et adoption. Cette prevalence d'hallucinations créé low confidence : **76% des développeurs** experiencing frequent hallucinations ont low confidence shipping AI code sans human checks. Même parmi ceux avec low hallucination rates, la majorité (75%) hésitent merger sans verification manuelle.

**Code Quality & AI Review : Catalyseur Clé**

Contrairement aux craintes, increased productivity avec IA corrèle souvent avec improved code quality. **70% des développeurs** experiencing considerable productivity gains reportent aussi better code quality. AI-powered code review agit comme catalyseur : **81% des fast-moving teams** utilisant AI pour review voient quality improvements, comparé à 55% sans. Cette validation automatisée permet maintenir standards qualité tout en accelerant delivery.

**Context : Driver Fondamental**

Le rapport identifie **context comme #1 driver** de qualité perçue et trust. **65% des développeurs** reportent que AI miss relevant context pendant refactoring, problème plus fréquent que hallucinations elles-mêmes. Similar issues surgissent dans test generation et code review. Developers overwhelmingly request "improved contextual understanding" de leurs AI tools. Le rapport advocate pour persistent, automated context learning across entire repository, car manual context selection est inefficient et frustrante.

**Le Confidence Flywheel**

Le rapport introduit "Confidence Flywheel" : cycle self-reinforcing où context-rich suggestions réduisent hallucinations, leading à accurate code, increased developer trust, faster shipping, et ultimately better examples feeding back dans model. Seulement **3.8%** des développeurs expérimentent actuellement ce scénario idéal, mais ceux qui le font reportent higher code quality gains et greater confidence.

**Testing & Confiance**

Developers utilisant AI pour testing sont **2x plus confiants** dans leurs test suites (**61% vs 27%** pour non-AI users), suggérant que comprehensive AI integration across development lifecycle améliore confiance overall.

**Conclusion Stratégique**

Qodo conclut qu'unlocking full business value de Generative AI requiert bridging gap entre LLM capabilities et proven existing systems, avec domain integration being critical. Le rapport advocate pour agentic code quality platform fournissant deep context awareness et integrating AI across development lifecycle pour enhance code quality et developer trust. Cette approach iterative, avec safeguards techniques et focus sur interactive documentation, est highly effective mais révèle aussi limitations : human technical expertise reste essentielle pour spot AI errors, et agents manquent business context.
